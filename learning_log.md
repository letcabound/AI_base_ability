2025-07-14：transformers中的PretrainedConfig使用，并在此基础上自定义ResNet50模型代码demo
            该类定义了模型构建中需要的所有超参数；通过该配置类(子类)以及模型结类(forward方法)，支持弹性构建新模型/结构。
            自定义模型并初始化训练之后，可将模型推送到 HuggingFace Hub。
2025-07-15：goal：MiniMind模型结构代码完成，然后开始训练
            reality：模型结构代码完成。（不应该每行代码都细看，要有目标。能应对面试和面试官）
2025-07-16：goal：完成训练模型过程。（魔搭平台上）
            reality: 整个训练过程分多步。完成了第一步训练：数据集验证、预训练过程。并测试。/ 发现了data whale大模型学习社区和资料

2025-07-17：goal：完成 sft 阶段，了解 第三阶段全流程以及数据构建。
            reality: 完成 sft 阶段，发现效果不太好。下载作者该阶段的模型权重测试，较好但也效果不好。
                    决定 直接转到 企业实用,现有模型微调；data whale的 self-llm系列。
2025-07-18：goal：完成self-llm的 环境配置、部署使用 部分。
            reality:环境配置、部署使用。（本地模型调用的批量返回没试过，但是服务器的vllm部署支持该功能。）  


 














反思总结：
不应该每行都细看，反而以 面试为目的，以应对为目的 更为适合和有效。并且获得机会后，在新环境中实践必然环境更合适。
            