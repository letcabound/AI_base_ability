环境配置、部署使用、微调。
# 1.qwen 文本生成模型系列概览(Qwen-3标准)
&emsp;&emsp;xxxx-base：如：Qwen3-8B-base。经过大量语料进行无监督预训练的基础语言模型。主要用于做情景学习或下游任务微调。<br/>
&emsp;&emsp;xxxx：如：Qwen3-32B。指令微调基模型，专门设计用于理解并以对话风格执行特定指令的模型。这些模型经过微调，能准确地解释用户命令，并能以更高的准确性和一致性执行诸如摘要、翻译和问答等任务。与在大量文本语料库上训练的基础模型不同，指令调优模型会使用包含指令示例及其预期结果的数据集进行额外训练，通常涵盖多个回合。这种训练方式使它们非常适合需要特定功能的应用，同时保持生成流畅且连贯文本的能力。

# 2.模型部署使用
```angular2html
https://github.com/datawhalechina/self-llm/tree/master/models
上述Qwen2.5 和 Qwen3目录的前两个Demo：本地模型对外提供api,本地模型兼容LangChain。

流式返回设置参数；

批量预测？？？
```







    
# 3.docker部署 LLM、Embedding、Rerank模型
## 3.1 LLM模型
```angular2html
# docker部署 deepseek-v3-0324
docker run --gpus all \
  -e CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 \
  --name deepseek-v3-0324 \
  --privileged \
  --shm-size=512g \
  -v /home/aicc/model_from_hf/deepseek-ai/deepseek-v3-0324:/model \
  -v /home/aicc/model_from_hf:/home/aicc/model_from_hf \
  -p 1025:1025 \
  --ipc=host \
  -e HF_ENDPOINT="https://hf-mirror.com" \
  -e TRANSFORMERS_CACHE="/home/aicc/model_from_hf" \
  -e HF_HOME="/home/aicc/model_from_hf" \
  -e HUGGINGFACE_HUB_CACHE="/home/aicc/model_from_hf" \
  -d \
  vllm/vllm-openai:latest \
  --served-model-name deepseek-v3-0324 \
  --model /model \
  --tokenizer /model \
  --port 1025 \
  --dtype auto \
  --tensor-parallel-size 8 \
  --trust-remote-code
```
```angular2html
# docker部署 deepseek-r1
docker run --gpus all \
  -e CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 \
  --name deepseek-r1 \
  --privileged \
  --shm-size=512g \
  -v /data/DeepSeek-R1:/model \
  -p 1025:1025 \
  --ipc=host \
  -d \
  vllm/vllm-openai:latest \
  --served-model-name deepseek-r1 \
  --model /model \
  --tokenizer /model \
  --port 1025 \
  --dtype auto \
  --tensor-parallel-size 8 \
  --trust-remote-code \
  --enable-reasoning \
  --reasoning-parser deepseek_r1
```
```angular2html
# 测试单条数据
curl -X POST "http://0.0.0.0:1025/v1/chat/completions" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "deepseek-r1",
    "messages": [
      {"role": "user", "content": "甲乙两班共有学生98人，甲班比乙班多6人，求两班各有多少人？"}
    ],
    "max_tokens": 512,
    "temperature": 0
  }'

# 压测
evalscope perf --url 'http://0.0.0.0:1025/v1/chat/completions' \
--parallel 128 \
--model 'deepseek-r1' \
--log-every-n-query 10 \
--read-timeout=1200 \
--dataset-path '/data/open_qa.jsonl' \
-n 1000 \
--max-prompt-length 32000 \
--api openai \
--stop '<|im_end|>' \
--dataset openqa \
--stream
```
## 3.2 Embedding模型
```angular2html
# docker部署 Embedding模型
docker run --gpus all \
-e CUDA_VISIBLE_DEVICES=4 \
--name jina-embeddings-v3 \
--privileged \
--shm-size=64g \
-v /home/aicc/model_from_hf/jinaai/jina-embeddings-v3:/model \
-v /home/aicc/model_from_hf:/home/aicc/model_from_hf \
-p 1026:1026 \
--ipc=host \
-e HF_ENDPOINT="https://hf-mirror.com" \
-e TRANSFORMERS_CACHE="/home/aicc/model_from_hf" \
-e HF_HOME="/home/aicc/model_from_hf" \
-e HUGGINGFACE_HUB_CACHE="/home/aicc/model_from_hf" \
-d \
vllm/vllm-openai:latest \
--served-model-name jina-embeddings-v3 \
--model /model \
--tokenizer /model \
--port 1026 \
--dtype auto \
--trust-remote-code \
--task embed
```
```angular2html
# 测试 Embedding模型
curl -X POST \
  'http://localhost:1026/v1/embeddings' \
  -H 'accept: application/json' \
  -H 'Content-Type: application/json' \
  -d '{
  "model": "jina-embeddings-v3",
  "input": "What is the capital of China?"
}'
```
## 3.3 Rerank模型
```angular2html
# docker部署 Rerank模型
docker run --gpus all \
  -e CUDA_VISIBLE_DEVICES=2 \
  --name jina-reranker-v2-base-multilingual \
  --privileged \
  --shm-size=64g \
  -v /data/aicc01/jinaai/jina-reranker-v2-base-multilingual:/model \
  -v /data/aicc01:/data/aicc01 \
  -p 1027:1027 \
  --ipc=host \
  -e HF_ENDPOINT="https://hf-mirror.com" \
  -e TRANSFORMERS_CACHE="/data/aicc01" \
  -e HF_HOME="/data/aicc01" \
  -e HUGGINGFACE_HUB_CACHE="/data/aicc01" \
  -d \
  vllm/vllm-openai:latest \
  --served-model-name jina-reranker-v2-base-multilingual \
  --model /model \
  --tokenizer /model \
  --port 1027 \
  --dtype auto \
  --trust-remote-code \
  --task score
```
```angular2html
# 测试 Rerank模型
curl -X POST \
  'http://localhost:1027/v1/rerank' \
  -H 'accept: application/json' \
  -H 'Content-Type: application/json' \
  -d '{
  "model": "jina-reranker-v2-base-multilingual",
  "query": "A man is eating pasta.",
  "documents": [
    "A man is eating food.",
    "A man is eating a piece of bread.",
    "The girl is carrying a baby.",
    "A man is riding a horse.",
    "A woman is playing violin."
  ]
}'
```


# 微调
预训练：用大量预料文本进行无监督学习预训练。<br>
有监督微调SFT：强化指令遵循能力，理解自然语言指令。<br>
强化学习微调：主要是对齐人类偏好，也可以进一步减少幻觉和有害内容。<br>
模型蒸馏：把经过RL的老师模型的行为教给一个更小更快的学生模型，跳过复杂的RL过程，减少推理开销。<br>

